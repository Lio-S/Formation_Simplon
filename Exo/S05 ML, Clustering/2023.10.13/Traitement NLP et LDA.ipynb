{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZElion\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le jeu de données 20newsgroups\n",
    "data_20newsgroups = fetch_20newsgroups()\n",
    "\n",
    "# Diviser le jeu de données en ensembles d'entraînement et de test\n",
    "X_train, X_test = train_test_split(data_20newsgroups.data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une représentation vectorielle des documents par CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1000, max_df=10, min_df=5, stop_words='english')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une représentation vectorielle des documents par TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,min_df=5,stop_words=\"english\",max_features=1000,)\n",
    "X_train_vectorized = vectorizer.fit_transform(data_20newsgroups.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Modèle LDA\n",
    "lda = LatentDirichletAllocation(n_components=20, random_state=42)\n",
    "lda.fit(X_train_vectorized)\n",
    "\n",
    "# Attribuer les documents de l'ensemble d'entraînement à des sujets\n",
    "train_topic_assignments_lda = lda.transform(X_train_vectorized)\n",
    "\n",
    "# Attribuer les documents de l'ensemble de test à des sujets\n",
    "test_topic_assignments_lda = lda.transform(X_test_vectorized)\n",
    "\n",
    "# Calculer le score de silhouette pour LDA\n",
    "silhouette_lda = silhouette_score(test_topic_assignments_lda, test_topic_assignments_lda.argmax(axis=1))\n",
    "print(f\"Silhouette LDA Score: {silhouette_lda}\")\n",
    "\n",
    "# Utiliser le modèle IsolationForest pour évaluer la pertinence de l'entraînement sur les données de test\n",
    "isolation_forest = IsolationForest(random_state=42)\n",
    "isolation_forest.fit(test_topic_assignments_lda)\n",
    "outliers_lda = isolation_forest.predict(test_topic_assignments_lda)\n",
    "outlier_percentage_lda = list(outliers_lda).count(-1) / len(outliers_lda)\n",
    "print(f\"Outlier Percentage: {outlier_percentage_lda}\")\n",
    "\n",
    "topic_word_distributions_lda = lda.components_\n",
    "topics = []\n",
    "for topic_idx, topic_words in enumerate(topic_word_distributions_lda):\n",
    "    top_words = [list(vectorizer.vocabulary_.keys())[i] for i in topic_words.argsort()[:-6:-1]]\n",
    "    topics.append(', '.join(top_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZElion\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics assignement Train : [[1.00208270e+00 3.42692282e+02 1.56211395e+02 ... 7.64329772e+01\n",
      "  3.55246393e+01 2.13541565e+01]\n",
      " [3.29958639e+01 3.44276052e+02 1.59655880e+02 ... 8.32466216e+01\n",
      "  4.84767986e+01 3.92937654e+01]\n",
      " [6.95294326e-02 3.42690823e+02 1.56208194e+02 ... 7.64264352e+01\n",
      "  3.55105618e+01 2.13307290e+01]\n",
      " ...\n",
      " [6.95294326e-02 3.42690823e+02 1.56208194e+02 ... 7.64264352e+01\n",
      "  3.55105618e+01 2.13307290e+01]\n",
      " [6.95294326e-02 3.42690823e+02 1.56208194e+02 ... 7.64264352e+01\n",
      "  3.55105618e+01 2.13307290e+01]\n",
      " [6.95294326e-02 3.42690823e+02 1.56208194e+02 ... 7.64264352e+01\n",
      "  3.55105618e+01 2.13307290e+01]] \n",
      "\n",
      "Topics assignement Train Shape : (9051, 20)\n",
      "Topics assignement Test : <memory at 0x000001C384FEC040>\n",
      "Topics assignement Test Shape : (2263,)\n",
      "Silhouette Kmean Score: 0.8923140604238557\n",
      "Outlier Percentage: 0.0883880234228262\n",
      "Topics : \n",
      " ['sumgait, mamma, nyr, har, vitamin', 'a86, 2di, 2tm, okz, bxn', 'w7, chz, 3dy, t7, tl', '75u, 2j, giz, a86, r8f', 'a86, 6um, 2di, 75u, 6t', '7ey, giz, 2tm, qax, 7kn', 'c_, s6, w7, chz, k8', 'a86, 75u, 2di, mg9v, giz', '2di, 75u, a86, 16m, t5', 'w7, t7, a7, chz, k8', '2q, 2pu, tl, 4u, kjz', 'uuencode, obfuscated, newline, argc, toad', 'xfree86, svr4, 386bsd, ecf, targa', 'hiv, infected, vaccine, providers, institutes', '75u, giz, okz, 7ey, fyn', '0c, l5, u8, q0, h0', 'bxn, 7ey, 1d9l, 7ex, g9', 'gfci, cec, insulation, prong, conductor', 'sizeof, toplevel, arg, xtpointer, dpy', 'libxmu, xmu, wg2, waii, se05']\n",
      "Top_W : \n",
      " ['libxmu', 'xmu', 'wg2', 'waii', 'se05']\n",
      "Labels KMeans : \n",
      " [0 0 0 ... 0 0 0]\n",
      "Features KMeans : \n",
      " ['kmeans0' 'kmeans1' 'kmeans2' 'kmeans3' 'kmeans4' 'kmeans5' 'kmeans6'\n",
      " 'kmeans7' 'kmeans8' 'kmeans9' 'kmeans10' 'kmeans11' 'kmeans12' 'kmeans13'\n",
      " 'kmeans14' 'kmeans15' 'kmeans16' 'kmeans17' 'kmeans18' 'kmeans19']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.00208270e+00, 3.42692282e+02, 1.56211395e+02, ...,\n",
       "        7.64329772e+01, 3.55246393e+01, 2.13541565e+01],\n",
       "       [3.29958639e+01, 3.44276052e+02, 1.59655880e+02, ...,\n",
       "        8.32466216e+01, 4.84767986e+01, 3.92937654e+01],\n",
       "       [6.95294326e-02, 3.42690823e+02, 1.56208194e+02, ...,\n",
       "        7.64264352e+01, 3.55105618e+01, 2.13307290e+01],\n",
       "       ...,\n",
       "       [6.95294326e-02, 3.42690823e+02, 1.56208194e+02, ...,\n",
       "        7.64264352e+01, 3.55105618e+01, 2.13307290e+01],\n",
       "       [6.95294326e-02, 3.42690823e+02, 1.56208194e+02, ...,\n",
       "        7.64264352e+01, 3.55105618e+01, 2.13307290e+01],\n",
       "       [6.95294326e-02, 3.42690823e+02, 1.56208194e+02, ...,\n",
       "        7.64264352e+01, 3.55105618e+01, 2.13307290e+01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ Modèle Kmean\n",
    "kmeans_ = KMeans(n_clusters=20,max_iter=100,)\n",
    "\n",
    "kmeans_.fit(X_train_vectorized)\n",
    "\n",
    "# Attribuer les documents de l'ensemble d'entraînement à des sujets\n",
    "train_topic_assignments_K = kmeans_.transform(X_train_vectorized)\n",
    "print(\"Topics assignement Train :\",train_topic_assignments_K,\"\\n\")\n",
    "print(\"Topics assignement Train Shape :\",train_topic_assignments_K.shape)\n",
    "# Attribuer les documents de l'ensemble de test à des sujets\n",
    "test_topic_assignments_K = kmeans_.predict(X_test_vectorized)\n",
    "print(\"Topics assignement Test :\",test_topic_assignments_K.data)\n",
    "print(\"Topics assignement Test Shape :\",test_topic_assignments_K.shape)\n",
    "\n",
    "# Calculer le score de silhouette pour KMeans\n",
    "silhouette_kmean = silhouette_score(X_train_vectorized, kmeans_.labels_)\n",
    "print(f\"Silhouette Kmean Score: {silhouette_kmean}\")\n",
    "\n",
    "# Utiliser le modèle IsolationForest pour évaluer la pertinence de l'entraînement sur les données de test\n",
    "isolation_forest = IsolationForest(random_state=42)\n",
    "isolation_forest.fit(train_topic_assignments_K)\n",
    "outliers_k = isolation_forest.predict(train_topic_assignments_K)\n",
    "outlier_percentage_k = list(outliers_k).count(-1) / len(outliers_k)\n",
    "print(f\"Outlier Percentage: {outlier_percentage_k}\")\n",
    "\n",
    "topic_word_distributions_k = kmeans_.cluster_centers_\n",
    "topics = []\n",
    "for topic_idx, topic_words_k in enumerate(topic_word_distributions_k):\n",
    "    top_words_k = [list(vectorizer.get_feature_names_out())[i] for i in topic_words_k.argsort()[:-6:-1]]\n",
    "    topics.append(', '.join(top_words_k))\n",
    "\n",
    "print(\"Topics :\",\"\\n\",topics)\n",
    "print(\"Top_W :\",\"\\n\",top_words_k)\n",
    "print(\"Labels KMeans :\",\"\\n\",kmeans_.labels_)\n",
    "print(\"Features KMeans :\",\"\\n\",kmeans_.get_feature_names_out())\n",
    "train_topic_assignments_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les clusters d'entraînement et les prédictions sur les données de test en 3D Statique\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Coordonnées des sujets d'entraînement\n",
    "train_x = train_topic_assignments_lda[:, 0]\n",
    "train_y = train_topic_assignments_lda[:, 1]\n",
    "train_z = train_topic_assignments_lda[:, 2]\n",
    "ax.scatter(train_x, train_y, train_z, c='blue', label='Train Clusters')\n",
    "\n",
    "# Coordonnées des sujets de test\n",
    "test_x = test_topic_assignments_lda[:, 0]\n",
    "test_y = test_topic_assignments_lda[:, 1]\n",
    "test_z = test_topic_assignments_lda[:, 2]\n",
    "ax.scatter(test_x, test_y, test_z, c='red', label='Test Predictions')\n",
    "\n",
    "ax.set_xlabel('Topic 1')\n",
    "ax.set_ylabel('Topic 2')\n",
    "ax.set_zlabel('Topic 3')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les clusters d'entraînement et les prédictions LDA sur les données de test en 3D Dynamique\n",
    "# Créer les coordonnées x, y et z pour chaque point de données\n",
    "x_train = train_topic_assignments_lda[:, 0]\n",
    "y_train = train_topic_assignments_lda[:, 1]\n",
    "z_train = train_topic_assignments_lda[:, 2]\n",
    "\n",
    "x_test = test_topic_assignments_lda[:, 0]\n",
    "y_test = test_topic_assignments_lda[:, 1]\n",
    "z_test = test_topic_assignments_lda[:, 2]\n",
    "\n",
    "# Afficher les clusters trouvés lors de l'entraînement en 3D\n",
    "lda_labels = KMeans(n_clusters=10, random_state=0).fit_predict(train_topic_assignments_lda)\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(x=x_train, y=y_train, z=z_train, mode='markers', marker=dict(size=2, opacity=0.7, color=lda_labels),name='Train'),\n",
    "    go.Scatter3d(x=x_test, y=y_test, z=z_test, mode='markers', marker=dict(size=2, opacity=0.7, color=lda_labels),name='Test')\n",
    "])\n",
    "fig.update_layout(scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les clusters d'entraînement et les prédictions KMeans sur les données de test en 3D Dynamique\n",
    "# Créer les coordonnées x, y et z pour chaque point de données\n",
    "x_train = train_topic_assignments_K[:, 0]\n",
    "y_train = train_topic_assignments_K[:, 1]\n",
    "z_train = train_topic_assignments_K[:, 2]\n",
    "\n",
    "x_test = test_topic_assignments_K[:, 0]\n",
    "y_test = test_topic_assignments_K[:, 1]\n",
    "z_test = test_topic_assignments_K[:, 2]\n",
    "\n",
    "# Afficher les clusters trouvés lors de l'entraînement en 3D\n",
    "cluster_labels = KMeans(n_clusters=10, random_state=0).fit_predict(train_topic_assignments_K)\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(x=x_train, y=y_train, z=z_train, mode='markers', marker=dict(size=2, opacity=0.7, color=cluster_labels),name='Train'),\n",
    "    go.Scatter3d(x=x_test, y=y_test, z=z_test, mode='markers', marker=dict(size=2, opacity=0.7, color=cluster_labels),name='Test')\n",
    "])\n",
    "fig.update_layout(scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'))\n",
    "# fig.(*cluster_labels.item(), title='Clusters')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups()\n",
    "df = pd.DataFrame()\n",
    "df[\"data\"] = dataset[\"data\"]\n",
    "df[\"target\"] = dataset[\"target\"]\n",
    "df[\"target_names\"] = df.target.apply(lambda row: dataset[\"target_names\"][row])\n",
    "df.head()\n",
    "\n",
    "def clean_text(text):\n",
    "    return \" \".join([ Word(word).lemmatize() for word in re.sub(\"[^A-Za-z0-9]+\", \" \", text).lower().split() if word not in stopword])    \n",
    "\n",
    "df[\"data_str\"] = df.data.apply(lambda row: clean_text(row) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "perp_components = defaultdict(dict)\n",
    "for i in [10,30,50,100]:\n",
    "    for ngram in [(1,1),(1,2),(1,3),(2,2),(3,3)]:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram, max_features= 2**10)\n",
    "        text_to_vector = vectorizer.fit_transform(data.data_str.values)\n",
    "        print(\"Ngram \",ngram )\n",
    "        print(\"Perplexity \", i)\n",
    "        X_embedded = TSNE(init=\"random\",perplexity=i ).fit_transform(text_to_vector)\n",
    "        ngram_str = str(ngram[0])+\"_\"+str(ngram[1])\n",
    "        perp_components[i][ngram_str] = X_embedded\n",
    "        # sns settings\n",
    "        sns.set(rc={'figure.figsize':(15,15)})\n",
    "        # colors\n",
    "        palette = sns.color_palette(\"hls\", len(set(df.target_names.values.tolist())))        \n",
    "        y = df.target_names.values.tolist()\n",
    "        # plot\n",
    "        sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y, legend='full', palette=palette)\n",
    "        title = \"t-SNE- 20News group - TfIdf - \"+ngram_str+\"- tSNE perplexity - \"+str(i)\n",
    "        plt.savefig(title)\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
